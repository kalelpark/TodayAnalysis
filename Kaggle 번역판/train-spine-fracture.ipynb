{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\nü¶¥ 1. Imports, constants, dependencies ü¶¥\n</div>","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"try:\n    import pylibjpeg\nexcept:\n    # The following *.whl files were collected from these pip packages:\n    #!pip install -U \"python-gdcm\" pydicom pylibjpeg    # Required for JPEG decompression. See: https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/discussion/341412\n    #!pip install -U torchvision                        # For EfficientNetV2\n\n    # Offline dependencies:\n    !mkdir -p /root/.cache/torch/hub/checkpoints/\n    !cp ../input/rsna-2022-whl/efficientnet_v2_s-dd5fe13b.pth  /root/.cache/torch/hub/checkpoints/\n    !pip install /kaggle/input/rsna-2022-whl/{pydicom-2.3.0-py3-none-any.whl,pylibjpeg-1.4.0-py3-none-any.whl,python_gdcm-3.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl}\n    !pip install /kaggle/input/rsna-2022-whl/{torch-1.12.1-cp37-cp37m-manylinux1_x86_64.whl,torchvision-0.13.1-cp37-cp37m-manylinux1_x86_64.whl}","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:31:40.512260Z","iopub.execute_input":"2022-09-03T10:31:40.512635Z","iopub.status.idle":"2022-09-03T10:33:00.721030Z","shell.execute_reply.started":"2022-09-03T10:31:40.512604Z","shell.execute_reply":"2022-09-03T10:33:00.719076Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import gc\nimport glob\nimport os\nimport re\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pydicom as dicom\nimport torch\nimport torchvision as tv\nfrom sklearn.model_selection import GroupKFold\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torchvision.models.feature_extraction import create_feature_extractor\nfrom tqdm.notebook import tqdm\n\nplt.rcParams['figure.figsize'] = (20, 5)\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 1000)\n\n# Effnet\nWEIGHTS = tv.models.efficientnet.EfficientNet_V2_S_Weights.DEFAULT\nRSNA_2022_PATH = '../input/rsna-2022-cervical-spine-fracture-detection'\nTRAIN_IMAGES_PATH = f'{RSNA_2022_PATH}/train_images'\nTEST_IMAGES_PATH = f'{RSNA_2022_PATH}/test_images'\nEFFNET_MAX_TRAIN_BATCHES = 4000\nEFFNET_MAX_EVAL_BATCHES = 200\nONE_CYCLE_MAX_LR = 0.0001\nONE_CYCLE_PCT_START = 0.3\nSAVE_CHECKPOINT_EVERY_STEP = 1000\nEFFNET_CHECKPOINTS_PATH = '../input/rsna-2022-base-effnetv2'\nFRAC_LOSS_WEIGHT = 2.\nN_FOLDS = 5\nMETADATA_PATH = '../input/vertebrae-detection-checkpoints'\n\nPREDICT_MAX_BATCHES = 1e9\n\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nif DEVICE == 'cuda':\n    BATCH_SIZE = 32\nelse:\n    BATCH_SIZE = 2","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:00.727431Z","iopub.execute_input":"2022-09-03T10:33:00.729818Z","iopub.status.idle":"2022-09-03T10:33:02.842466Z","shell.execute_reply.started":"2022-09-03T10:33:00.729764Z","shell.execute_reply":"2022-09-03T10:33:02.841462Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(f'{RSNA_2022_PATH}/train.csv')\n\ndf_train_slices = pd.read_csv(f'{METADATA_PATH}/train_segmented.csv')\nc1c7 = [f'C{i}' for i in range(1, 8)]\ndf_train_slices[c1c7] = (df_train_slices[c1c7] > 0.5).astype(int)\n\ndf_train = df_train_slices.set_index('StudyInstanceUID').join(df_train.set_index('StudyInstanceUID'),\n                                                              rsuffix='_fracture').reset_index().copy()\n\ndf_train = df_train.query('StudyInstanceUID != \"1.2.826.0.1.3680043.20574\"').reset_index(drop=True)\ndf_train.sample(2)","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:02.844463Z","iopub.execute_input":"2022-09-03T10:33:02.845564Z","iopub.status.idle":"2022-09-03T10:33:05.644663Z","shell.execute_reply.started":"2022-09-03T10:33:02.845517Z","shell.execute_reply":"2022-09-03T10:33:05.643679Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"split = GroupKFold(N_FOLDS)\nfor k, (_, test_idx) in enumerate(split.split(df_train, groups=df_train.StudyInstanceUID)):\n    df_train.loc[test_idx, 'split'] = k\ndf_train.sample(2)","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:05.647179Z","iopub.execute_input":"2022-09-03T10:33:05.648113Z","iopub.status.idle":"2022-09-03T10:33:06.119335Z","shell.execute_reply.started":"2022-09-03T10:33:05.648073Z","shell.execute_reply":"2022-09-03T10:33:06.118363Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(f'{RSNA_2022_PATH}/test.csv')\n\nif df_test.iloc[0].row_id == '1.2.826.0.1.3680043.10197_C1':\n    df_test = pd.DataFrame({\n        \"row_id\": ['1.2.826.0.1.3680043.22327_C1', '1.2.826.0.1.3680043.25399_C1', '1.2.826.0.1.3680043.5876_C1'],\n        \"StudyInstanceUID\": ['1.2.826.0.1.3680043.22327', '1.2.826.0.1.3680043.25399', '1.2.826.0.1.3680043.5876'],\n        \"prediction_type\": [\"C1\", \"C1\", \"patient_overall\"]}\n    )\n\ndf_test","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:06.120949Z","iopub.execute_input":"2022-09-03T10:33:06.121323Z","iopub.status.idle":"2022-09-03T10:33:06.140100Z","shell.execute_reply.started":"2022-09-03T10:33:06.121288Z","shell.execute_reply":"2022-09-03T10:33:06.139216Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_slices = glob.glob(f'{TEST_IMAGES_PATH}/*/*')\ntest_slices = [re.findall(f'{TEST_IMAGES_PATH}/(.*)/(.*).dcm', s)[0] for s in test_slices]\ndf_test_slices = pd.DataFrame(data=test_slices, columns=['StudyInstanceUID', 'Slice'])\n\ndf_test = df_test.set_index('StudyInstanceUID').join(df_test_slices.set_index('StudyInstanceUID')).reset_index()","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:06.141608Z","iopub.execute_input":"2022-09-03T10:33:06.142328Z","iopub.status.idle":"2022-09-03T10:33:06.275973Z","shell.execute_reply.started":"2022-09-03T10:33:06.142284Z","shell.execute_reply":"2022-09-03T10:33:06.275005Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def load_dicom(path):\n    \n    img = dicom.dcmread(path)\n    img.PhotometricInterpretation = 'YBR_FULL'\n    data = img.pixel_array\n    data = data - np.min(data)\n    \n    if np.max(data) != 0:\n        data = data / np.max(data)\n        \n    data = (data * 255).astype(np.uint8)\n    \n    return cv2.cvtColor(data, cv2.COLOR_GRAY2RGB), img","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:06.277571Z","iopub.execute_input":"2022-09-03T10:33:06.278004Z","iopub.status.idle":"2022-09-03T10:33:06.286784Z","shell.execute_reply.started":"2022-09-03T10:33:06.277964Z","shell.execute_reply":"2022-09-03T10:33:06.285873Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class EffnetDataSet(torch.utils.data.Dataset):\n    def __init__(self, df, path, transforms=None):\n        super().__init__()\n        self.df = df\n        self.path = path\n        self.transforms = transforms\n\n    def __getitem__(self, i):\n        path = os.path.join(self.path, self.df.iloc[i].StudyInstanceUID, f'{self.df.iloc[i].Slice}.dcm')\n\n        try:\n            img = load_dicom(path)[0]\n            img = np.transpose(img, (2, 0, 1))\n            if self.transforms is not None:\n                img = self.transforms(torch.as_tensor(img))\n        except Exception as ex:\n            print(ex)\n            return None\n\n        if 'C1_fracture' in self.df:\n            frac_targets = torch.as_tensor(self.df.iloc[i][['C1_fracture', 'C2_fracture', 'C3_fracture', 'C4_fracture',\n                                                            'C5_fracture', 'C6_fracture', 'C7_fracture']].astype(\n                'float32').values)\n            vert_targets = torch.as_tensor(\n                self.df.iloc[i][['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']].astype('float32').values)\n            frac_targets = frac_targets * vert_targets  # we only enable targets that are visible on the current slice\n            return img, frac_targets, vert_targets\n        return img\n\n    def __len__(self):\n        return len(self.df)\n","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:06.288549Z","iopub.execute_input":"2022-09-03T10:33:06.288922Z","iopub.status.idle":"2022-09-03T10:33:06.299750Z","shell.execute_reply.started":"2022-09-03T10:33:06.288888Z","shell.execute_reply":"2022-09-03T10:33:06.298283Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"ds_train = EffnetDataSet(df_train, TRAIN_IMAGES_PATH, WEIGHTS.transforms())\nX, y_frac, y_vert = ds_train[42]\nprint(X.shape, y_frac.shape, y_vert.shape)","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:06.301912Z","iopub.execute_input":"2022-09-03T10:33:06.302334Z","iopub.status.idle":"2022-09-03T10:33:06.357817Z","shell.execute_reply.started":"2022-09-03T10:33:06.302300Z","shell.execute_reply":"2022-09-03T10:33:06.356174Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Only X values returned by the test dataset\nds_test = EffnetDataSet(df_test, TEST_IMAGES_PATH, WEIGHTS.transforms())\nX = ds_test[42]\nX.shape","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:06.361547Z","iopub.execute_input":"2022-09-03T10:33:06.361845Z","iopub.status.idle":"2022-09-03T10:33:06.393411Z","shell.execute_reply.started":"2022-09-03T10:33:06.361819Z","shell.execute_reply":"2022-09-03T10:33:06.392498Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class EffnetModel(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        effnet = tv.models.efficientnet_v2_s(weights = WEIGHTS)\n        self.model = create_feature_extractor(effnet, ['flatten'])\n        self.nn_fracture = torch.nn.Sequential(\n            torch.nn.Linear(1280, 7),\n        )\n        \n        self.nn_vertebrae = torch.nn.Sequential(\n            torch.nn.Linear(1280, 7),\n        )\n    \n    def forward(self, x):\n        x = self.model(x)['flatten']\n        \n        return self.nn_fracture(x), self.nn_vertebrae(x)\n    \n    def predict(self, x):\n        frac, vert = self.forward(x)\n        \n        return torch.sigmoid(frac), torch.sigmoid(vert)\n\nmodel = EffnetModel()\nmodel.predict(torch.randn(1, 3, 512, 512))\ndel model","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:06.394654Z","iopub.execute_input":"2022-09-03T10:33:06.394994Z","iopub.status.idle":"2022-09-03T10:33:08.377711Z","shell.execute_reply.started":"2022-09-03T10:33:06.394960Z","shell.execute_reply":"2022-09-03T10:33:08.376677Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def weighted_loss(y_pred_logit, y, reduction='mean', verbose=False):\n\n    neg_weights = (torch.tensor([7., 1, 1, 1, 1, 1, 1, 1]) if y_pred_logit.shape[-1] == 8 else torch.ones(y_pred_logit.shape[-1])).to(DEVICE)\n    pos_weights = (torch.tensor([14., 2, 2, 2, 2, 2, 2, 2]) if y_pred_logit.shape[-1] == 8 else torch.ones(y_pred_logit.shape[-1]) * 2.).to(DEVICE)\n\n    loss = torch.nn.functional.binary_cross_entropy_with_logits(\n        y_pred_logit,\n        y,\n        reduction='none',\n    )\n\n    if verbose:\n        print('loss', loss)\n\n    pos_weights = y * pos_weights.unsqueeze(0)\n    neg_weights = (1 - y) * neg_weights.unsqueeze(0)\n    all_weights = pos_weights + neg_weights\n\n    if verbose:\n        print('all weights', all_weights)\n\n    loss *= all_weights\n    if verbose:\n        print('weighted loss', loss)\n\n    norm = torch.sum(all_weights, dim=1).unsqueeze(1)\n    if verbose:\n        print('normalization factors', norm)\n\n    loss /= norm\n    if verbose:\n        print('normalized loss', loss)\n\n    loss = torch.sum(loss, dim=1)\n    if verbose:\n        print('summed up over patient_overall-C1-C7 loss', loss)\n\n    if reduction == 'mean':\n        return torch.mean(loss)\n    return loss","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:08.382362Z","iopub.execute_input":"2022-09-03T10:33:08.385132Z","iopub.status.idle":"2022-09-03T10:33:08.399280Z","shell.execute_reply.started":"2022-09-03T10:33:08.385094Z","shell.execute_reply":"2022-09-03T10:33:08.398132Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Quick test of  patient_overall + C1-C7 loss\nweighted_loss(\n    torch.logit(torch.tensor([\n        [0.1, 0.9, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n        [0.1, 0.9, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n    ])).to(DEVICE),\n    torch.tensor([\n        [1., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0, 0., 0., 0., 0., 0., 0.]\n    ]).to(DEVICE),\n    reduction=None,\n    verbose=True\n)","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:08.400621Z","iopub.execute_input":"2022-09-03T10:33:08.401284Z","iopub.status.idle":"2022-09-03T10:33:10.429962Z","shell.execute_reply.started":"2022-09-03T10:33:08.401205Z","shell.execute_reply":"2022-09-03T10:33:10.428756Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Quick test of C1-C7 loss\nweighted_loss(\n    torch.logit(torch.tensor([\n        [0.9, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n        [0.9, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n    ])).to(DEVICE),\n    torch.tensor([\n        [1., 0., 0., 0., 0., 0., 0.],\n        [0, 0., 0., 0., 0., 0., 0.]\n    ]).to(DEVICE),\n    reduction=None,\n    verbose=True\n)","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:10.432276Z","iopub.execute_input":"2022-09-03T10:33:10.433107Z","iopub.status.idle":"2022-09-03T10:33:10.460781Z","shell.execute_reply.started":"2022-09-03T10:33:10.433058Z","shell.execute_reply":"2022-09-03T10:33:10.459529Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def filter_nones(b):\n    return torch.utils.data.default_collate([v for v in b if v is not None])","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:10.462681Z","iopub.execute_input":"2022-09-03T10:33:10.463373Z","iopub.status.idle":"2022-09-03T10:33:10.469060Z","shell.execute_reply.started":"2022-09-03T10:33:10.463337Z","shell.execute_reply":"2022-09-03T10:33:10.467840Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def save_model(name, model):\n    torch.save(model.state_dict(), f'{name}.tph')","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:10.470746Z","iopub.execute_input":"2022-09-03T10:33:10.471692Z","iopub.status.idle":"2022-09-03T10:33:10.478593Z","shell.execute_reply.started":"2022-09-03T10:33:10.471634Z","shell.execute_reply":"2022-09-03T10:33:10.477366Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def load_model(model, name, path='.'):\n    data = torch.load(os.path.join(path, f'{name}.tph'), map_location=DEVICE)\n    model.load_state_dict(data)\n    return model\n\n\n# # quick test\n# model = torch.nn.Linear(2, 1)\n# save_model('testmodel', model)\n\n# model1 = load_model(torch.nn.Linear(2, 1), 'testmodel')\n# assert torch.all(\n#     next(iter(model1.parameters())) == next(iter(model.parameters()))\n# ).item(), \"Loading/saving is inconsistent!\"","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:10.480564Z","iopub.execute_input":"2022-09-03T10:33:10.481271Z","iopub.status.idle":"2022-09-03T10:33:10.488316Z","shell.execute_reply.started":"2022-09-03T10:33:10.481236Z","shell.execute_reply":"2022-09-03T10:33:10.487128Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def evaluate_effnet(model: EffnetModel, ds, max_batches=PREDICT_MAX_BATCHES, shuffle=False):\n    torch.manual_seed(42)\n    model = model.to(DEVICE)\n    dl_test = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=os.cpu_count(),\n                                          collate_fn=filter_nones)\n    pred_frac = []\n    pred_vert = []\n    \n    with torch.no_grad():\n        model.eval()\n        frac_losses = []\n        vert_losses = []\n        \n        with tqdm(dl_test, desc='Eval', miniters=10) as progress:\n            for i, (X, y_frac, y_vert) in enumerate(progress):\n                with autocast():\n                    y_frac_pred, y_vert_pred = model.forward(X.to(DEVICE))\n                    frac_loss = weighted_loss(y_frac_pred, y_frac.to(DEVICE)).item()\n                    vert_loss = torch.nn.functional.binary_cross_entropy_with_logits(y_vert_pred, y_vert.to(DEVICE)).item()\n                    pred_frac.append(torch.sigmoid(y_frac_pred))\n                    pred_vert.append(torch.sigmoid(y_vert_pred))\n                    frac_losses.append(frac_loss)\n                    vert_losses.append(vert_loss)\n\n                if i >= max_batches:\n                    break\n        return np.mean(frac_losses), np.mean(vert_losses), torch.concat(pred_frac).cpu().numpy(), torch.concat(pred_vert).cpu().numpy()\n\n# quick test\nm = EffnetModel()\nfrac_loss, vert_loss, pred1, pred2 = evaluate_effnet(m, ds_train, max_batches=2)\nfrac_loss, vert_loss, pred1.shape, pred2.shape","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:10.490220Z","iopub.execute_input":"2022-09-03T10:33:10.491156Z","iopub.status.idle":"2022-09-03T10:33:15.244430Z","shell.execute_reply.started":"2022-09-03T10:33:10.491122Z","shell.execute_reply":"2022-09-03T10:33:15.243212Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def gc_collect():\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:33:15.246873Z","iopub.execute_input":"2022-09-03T10:33:15.247581Z","iopub.status.idle":"2022-09-03T10:33:15.252699Z","shell.execute_reply.started":"2022-09-03T10:33:15.247540Z","shell.execute_reply":"2022-09-03T10:33:15.251657Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def train_effnet(ds_train, ds_test, name):\n    torch.manual_seed(42)\n    dl_train = torch.utils.data.DataLoader(ds_train, batch_size = BATCH_SIZE, shuffle = True, num_workers = os.cpu.count(),\n                                          collate_fn = filter_nones)\n    \n    model = EffnetModel().to(DEVICE)\n    optim = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr = ONE_CYCLE_MAX_LR, epochs = 1,\n                                                steps_per_epoch = min(EFFNET_MAX_TRAIN_BATCHES, len(dl_train)),\n                                                pct_start = ONE_CYCLE_PCT_START)\n    \n    model.train()\n    sclaer = GradScaler()\n    with tqdm(dl_train, desc='Train', miniters=10) as progress:\n        for batch_idx, (X, y_frac, y_vert) in enumerate(progress):\n            if ds_eval is not None and batch_idx % SAVE_CHECKPOINT_EVERY_STEP == 0 and EFFNET_MAX_EVAL_BATCHES > 0:\n                frac_loss, vert_loss = evaluate_effnet(\n                    model, ds_eval, max_batches = EFFNET_MAX_EVAL_BATCHES, shuffle = True)[:2]\n                \n                model.train()\n                \n                if batch_idx > 0:\n                    save_model(name, model)\n            \n            if batch_idx >= EFFNET_MAX_TRAIN_BATCHES:\n                break\n            \n            optim.zero_grad()\n            \n            with autocast():\n                y_frac_pred, y_vert_pred = model.forward(x.to(DEVICE))\n                frac_loss = weighted_loss(y_frac_pred, y_frac.to(DEVICE))\n                vert_loss = weighted_loss(y_vert_pred, y_vert.to(DEVICE))\n                \n                loss = FRAC_LOSS_WEIGHT * frac_loss + vert_loss\n                \n                if np.isinf(loss.item() or np.isna(loss.item())):\n                    print(f'Bad loss, skipping the batch {batch_idx}')\n                    del loss, frac_loss, vert_loss, y_frac_pred, y_vert_pred\n                    gc_collect()\n                    continue\n                \n            scaler.scale(loss).backward()\n            scaler.step(optim)\n            scaler.update()\n            scheduler.step()\n            \n            progress.set_description(f'Train loss: {loss.item() :.02f}')\n    \n    save_model(name, model)\n    return model\n\n\neffnet_models = []\nfor fold in range(N_FOLDS):\n    if os.path.exists(os.path.join(EFFNET_CHECKPOINTS_PATH, f'effnetv2-f{fold}.tph')):\n        print(f'Found cached version of effnetv2-f{fold}')\n        effnet_models.append(load_model(EffnetModel(), f'effnetv2-f{fold}', EFFNET_CHECKPOINTS_PATH))\n        \n    else:\n        gc.collect()\n        ds_train = EffnetDataSet(df_train.query('split != @fold'), TRAIN_IMAGES_PATH, WEIGHTS.transforms())\n        ds_eval = EffnetDataSet(df_train.query('split == @fold'), TRAIN_IMAGES_PATH, WEIGHTS.transforms())\n        effnet_models.append(train_effnet(ds_train, ds_eval, run, f'effnetv2-f{fold}'))\n\n\n\nif os.path.exists(os.path.join(EFFNET_CHECKPOINTS_PATH, f'effnetv2.tph')):\n    print(f'Found cached version of effnetv2')\n    effnet_models.append(load_model(EffnetModel(), f'effnetv2', EFFNET_CHECKPOINTS_PATH))","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:53:55.452458Z","iopub.execute_input":"2022-09-03T10:53:55.452896Z","iopub.status.idle":"2022-09-03T10:54:08.396146Z","shell.execute_reply.started":"2022-09-03T10:53:55.452863Z","shell.execute_reply":"2022-09-03T10:54:08.395127Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-success\" style=\"font-size:25px\">\n    ü¶¥ 6. Evaluation ü¶¥\n</div>\n\nWe cross-validate our final model here using 5 folds.\n1. We generate prediction for every holdout set for every fold.\n2. Predictions are aggregated using the non-parametric model.\n3. Final results are produced using the `weighted_loss`","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"effnet_models = []\nfor name in tqdm(range(N_FOLDS)):\n    effnet_models.append(load_model(EffnetModel(), f'effnetv2-f{name}', EFFNET_CHECKPOINTS_PATH))","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:55:55.856398Z","iopub.execute_input":"2022-09-03T10:55:55.856786Z","iopub.status.idle":"2022-09-03T10:56:01.364526Z","shell.execute_reply.started":"2022-09-03T10:55:55.856754Z","shell.execute_reply":"2022-09-03T10:56:01.363541Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def gen_effnet_predictions(effnet_models, df_train):\n    if os.path.exists(os.path.join(EFFNET_CHECKPOINTS_PATH, 'train_predictions.csv')):\n        print('Found cached version of train_predictions.csv')\n        df_train_predictions = pd.read_csv(os.path.join(EFFNET_CHECKPOINTS_PATH, 'train_predictions.csv'))\n    else:\n        df_train_predictions = []\n        with tqdm(enumerate(effnet_models), total=len(effnet_models), desc='Folds') as progress:\n            for fold, effnet_model in progress:\n                ds_eval = EffnetDataSet(df_train.query('split == @fold'), TRAIN_IMAGES_PATH, WEIGHTS.transforms())\n\n                frac_loss, vert_loss, effnet_pred_frac, effnet_pred_vert = evaluate_effnet(effnet_model, ds_eval, PREDICT_MAX_BATCHES)\n                progress.set_description(f'Fold score:{frac_loss:.02f}')\n                df_effnet_pred = pd.DataFrame(data=np.concatenate([effnet_pred_frac, effnet_pred_vert], axis=1),\n                                              columns=[f'C{i}_effnet_frac' for i in range(1, 8)] +\n                                                      [f'C{i}_effnet_vert' for i in range(1, 8)])\n\n                df = pd.concat(\n                    [df_train.query('split == @fold').head(len(df_effnet_pred)).reset_index(drop=True), df_effnet_pred],\n                    axis=1\n                ).sort_values(['StudyInstanceUID', 'Slice'])\n                df_train_predictions.append(df)\n        df_train_predictions = pd.concat(df_train_predictions)\n    return df_train_predictions","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T10:57:23.442602Z","iopub.execute_input":"2022-09-03T10:57:23.442975Z","iopub.status.idle":"2022-09-03T10:57:23.453651Z","shell.execute_reply.started":"2022-09-03T10:57:23.442944Z","shell.execute_reply":"2022-09-03T10:57:23.452538Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df_pred = gen_effnet_predictions(effnet_models, df_train)\ndf_pred.to_csv('train_predictions.csv', index=False)\ndf_pred","metadata":{"pycharm":{"name":"#%%\n","is_executing":true},"execution":{"iopub.status.busy":"2022-09-03T10:57:28.799397Z","iopub.execute_input":"2022-09-03T10:57:28.799770Z","iopub.status.idle":"2022-09-03T10:57:45.912924Z","shell.execute_reply.started":"2022-09-03T10:57:28.799740Z","shell.execute_reply":"2022-09-03T10:57:45.912031Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"target_cols = ['patient_overall'] + [f'C{i}_fracture' for i in range(1, 8)]\nfrac_cols = [f'C{i}_effnet_frac' for i in range(1, 8)]\nvert_cols = [f'C{i}_effnet_vert' for i in range(1, 8)]\n\n\ndef patient_prediction(df):\n    c1c7 = np.average(df[frac_cols].values, axis=0, weights=df[vert_cols].values)\n    pred_patient_overall = 1 - np.prod(1 - c1c7)\n    return np.concatenate([[pred_patient_overall], c1c7])\n\ndf_patient_pred = df_pred.groupby('StudyInstanceUID').apply(lambda df: patient_prediction(df)).to_frame('pred').join(df_pred.groupby('StudyInstanceUID')[target_cols].mean())","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T11:01:12.615668Z","iopub.execute_input":"2022-09-03T11:01:12.616257Z","iopub.status.idle":"2022-09-03T11:01:15.765543Z","shell.execute_reply.started":"2022-09-03T11:01:12.616222Z","shell.execute_reply":"2022-09-03T11:01:15.764548Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df_patient_pred","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T11:01:15.770966Z","iopub.execute_input":"2022-09-03T11:01:15.773189Z","iopub.status.idle":"2022-09-03T11:01:15.810519Z","shell.execute_reply.started":"2022-09-03T11:01:15.773152Z","shell.execute_reply":"2022-09-03T11:01:15.809701Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"predictions = np.stack(df_patient_pred.pred.values.tolist())\npredictions","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T11:02:53.198142Z","iopub.execute_input":"2022-09-03T11:02:53.198514Z","iopub.status.idle":"2022-09-03T11:02:53.211216Z","shell.execute_reply.started":"2022-09-03T11:02:53.198462Z","shell.execute_reply":"2022-09-03T11:02:53.210137Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"targets = df_patient_pred[target_cols].values\ntargets","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T11:02:54.323154Z","iopub.execute_input":"2022-09-03T11:02:54.324202Z","iopub.status.idle":"2022-09-03T11:02:54.333413Z","shell.execute_reply.started":"2022-09-03T11:02:54.324164Z","shell.execute_reply":"2022-09-03T11:02:54.332269Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print('CV score:', weighted_loss(torch.logit(torch.as_tensor(predictions)).to(DEVICE), torch.as_tensor(targets).to(DEVICE)))","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-09-03T11:03:21.455945Z","iopub.execute_input":"2022-09-03T11:03:21.456533Z","iopub.status.idle":"2022-09-03T11:03:21.467277Z","shell.execute_reply.started":"2022-09-03T11:03:21.456474Z","shell.execute_reply":"2022-09-03T11:03:21.466150Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-danger\" style=\"text-align:center; font-size:20px;\">\n    ‚ù§Ô∏è Dont forget to ‚ñ≤upvote‚ñ≤ if you find this notebook usefull!  ‚ù§Ô∏è\n</div>","metadata":{"execution":{"iopub.execute_input":"2022-08-20T13:17:18.762083Z","iopub.status.busy":"2022-08-20T13:17:18.761536Z","iopub.status.idle":"2022-08-20T13:17:18.76993Z","shell.execute_reply":"2022-08-20T13:17:18.768312Z","shell.execute_reply.started":"2022-08-20T13:17:18.762038Z"},"pycharm":{"name":"#%% md\n"}}}]}