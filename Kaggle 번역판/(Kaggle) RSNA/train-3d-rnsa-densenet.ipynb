{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Libraries","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install -qU ../input/for-pydicom/python_gdcm-3.0.14-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl ../input/for-pydicom/pylibjpeg-1.4.0-py3-none-any.whl --find-links frozen_packages --no-index","metadata":{"execution":{"iopub.status.busy":"2022-09-04T09:45:18.118794Z","iopub.execute_input":"2022-09-04T09:45:18.119172Z","iopub.status.idle":"2022-09-04T09:45:27.802200Z","shell.execute_reply.started":"2022-09-04T09:45:18.119142Z","shell.execute_reply":"2022-09-04T09:45:27.801022Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"!pip install -q kaggle_vol3d_classify -f ../input/cervical-spine-fracture-detection-npz-3d-volumes/frozen_packages --no-index","metadata":{"execution":{"iopub.status.busy":"2022-09-04T09:45:27.805509Z","iopub.execute_input":"2022-09-04T09:45:27.806581Z","iopub.status.idle":"2022-09-04T09:45:38.329643Z","shell.execute_reply.started":"2022-09-04T09:45:27.806516Z","shell.execute_reply":"2022-09-04T09:45:38.328455Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# ---- efficientNet3D offline  ---\nimport torch.nn as nn\nimport sys\nsys.path.append('../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D')\nfrom efficientnet_pytorch_3d import EfficientNet3D","metadata":{"execution":{"iopub.status.busy":"2022-09-04T09:45:38.331374Z","iopub.execute_input":"2022-09-04T09:45:38.332074Z","iopub.status.idle":"2022-09-04T09:45:38.338550Z","shell.execute_reply.started":"2022-09-04T09:45:38.332027Z","shell.execute_reply":"2022-09-04T09:45:38.337465Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.patches as patches\nimport seaborn as sns\nsns.set(style='darkgrid', font_scale=1.6)\nimport cv2\nimport os\nfrom os import listdir\nimport re\nimport gc\nimport random\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom tqdm.auto import tqdm\nfrom pprint import pprint\nfrom time import time\nimport itertools\nfrom skimage import measure\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nimport nibabel as nib\nfrom glob import glob\nimport warnings\n#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n#warnings.filterwarnings(\"ignore\", category=UserWarning)\n#warnings.filterwarnings(\"ignore\", category=FutureWarning)\nimport zipfile\nfrom scipy import ndimage\nfrom sklearn.model_selection import train_test_split\nfrom joblib import Parallel, delayed\nfrom PIL import Image\nfrom dipy.denoise.nlmeans import nlmeans\nfrom dipy.denoise.noise_estimate import estimate_sigma\nfrom kaggle_volclassif.utils import interpolate_volume\nfrom skimage import exposure\nfrom sklearn.model_selection import GroupKFold\n\n# Pytorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport kornia\nimport kornia.augmentation as augmentation\n\nfrom sklearn.model_selection import GroupKFold\nfrom torch.cuda.amp import GradScaler, autocast\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:22:47.906098Z","iopub.execute_input":"2022-09-04T10:22:47.907236Z","iopub.status.idle":"2022-09-04T10:22:47.987547Z","shell.execute_reply.started":"2022-09-04T10:22:47.907165Z","shell.execute_reply":"2022-09-04T10:22:47.985694Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Set random seeds\ndef set_seed(seed=0):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\nset_seed()\n\nBATCH_SIZE = 16\nLEARNING_RATE = 0.0001\nN_EPOCHS = 20\nPATIENCE = 3\nEXPERIMENTAL = False\nAUGMENTATIONS = True\n\n# Config device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-09-04T11:44:34.242303Z","iopub.execute_input":"2022-09-04T11:44:34.242687Z","iopub.status.idle":"2022-09-04T11:44:34.252348Z","shell.execute_reply.started":"2022-09-04T11:44:34.242654Z","shell.execute_reply":"2022-09-04T11:44:34.251378Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"# ---- Train ----\n\ntrain_df = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/train.csv\")\ndf_train_slices = pd.read_csv('../input/vertebrae-detection-checkpoints/train_segmented.csv')\nc1c7 = [f'C{i}' for i in range(1, 8)]\ndf_train_slices[c1c7] = (df_train_slices[c1c7] > 0.5).astype(int)\ntrain_df = df_train_slices.set_index('StudyInstanceUID').join(train_df.set_index('StudyInstanceUID'), rsuffix='_fracture').reset_index().copy()\ntrain_df = train_df.query('StudyInstanceUID != \"1.2.826.0.1.3680043.20574\"').reset_index(drop=True)\n\nsplit = GroupKFold(5)\nfor k, (_, test_idx) in enumerate(split.split(train_df, groups=train_df.StudyInstanceUID)):\n    train_df.loc[test_idx, 'split'] = k","metadata":{"execution":{"iopub.status.busy":"2022-09-04T09:45:38.390156Z","iopub.execute_input":"2022-09-04T09:45:38.391757Z","iopub.status.idle":"2022-09-04T09:45:41.460113Z","shell.execute_reply.started":"2022-09-04T09:45:38.391731Z","shell.execute_reply":"2022-09-04T09:45:41.458741Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# ----- TEST ----\n\ntest_df = pd.read_csv(f'../input/rsna-2022-cervical-spine-fracture-detection/test.csv')\n\nif test_df.iloc[0].row_id == '1.2.826.0.1.3680043.10197_C1':\n    # test_images and test.csv are inconsistent in the dev dataset, fixing labels for the dev run.\n    test_df = pd.DataFrame({\n        \"row_id\": ['1.2.826.0.1.3680043.22327_C1', '1.2.826.0.1.3680043.25399_C1', '1.2.826.0.1.3680043.5876_C1'],\n        \"StudyInstanceUID\": ['1.2.826.0.1.3680043.22327', '1.2.826.0.1.3680043.25399', '1.2.826.0.1.3680043.5876'],\n        \"prediction_type\": [\"C1\", \"C1\", \"patient_overall\"]}\n    )\n\n\ntest_slices = glob('../input/rsna-2022-cervical-spine-fracture-detection/test_images/*/*')\ntest_slices = [re.findall('../input/rsna-2022-cervical-spine-fracture-detection/test_images/(.*)/(.*).dcm', s)[0] for s in test_slices]\ndf_test_slices = pd.DataFrame(data=test_slices, columns=['StudyInstanceUID', 'Slice'])\n    \ntest_df = test_df.set_index('StudyInstanceUID').join(df_test_slices.set_index('StudyInstanceUID')).reset_index()\ntest_df.sample(2)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T09:45:41.465638Z","iopub.execute_input":"2022-09-04T09:45:41.467810Z","iopub.status.idle":"2022-09-04T09:45:41.591951Z","shell.execute_reply.started":"2022-09-04T09:45:41.467766Z","shell.execute_reply":"2022-09-04T09:45:41.591084Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"if AUGMENTATIONS:\n    augs = transforms.Compose([\n        augmentation.RandomRotation3D((0,0,30), resample='bilinear', p=0.5, same_on_batch=False, keepdim=True),\n        #augmentation.RandomHorizontalFlip3D(same_on_batch=False, p=0.5, keepdim=True),\n        ])\nelse:\n    augs=None","metadata":{"execution":{"iopub.status.busy":"2022-09-04T09:45:41.593323Z","iopub.execute_input":"2022-09-04T09:45:41.593971Z","iopub.status.idle":"2022-09-04T09:45:41.601882Z","shell.execute_reply.started":"2022-09-04T09:45:41.593934Z","shell.execute_reply":"2022-09-04T09:45:41.600975Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Torch Dataset","metadata":{}},{"cell_type":"code","source":"class RSNADataset(torch.utils.data.Dataset):\n    def __init__(self, subset = 'train', df_table = train_df, transform = None):\n        super().__init__()\n        \n        self.subset = subset\n        self.df_table = df_table.reset_index(drop = True)\n        self.transform = transform\n#         self.targets = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'patient_overall']/\n        \n        \n        # Classification of two Dataset\n        fh_paths = glob(os.path.join('../input/rsna-3d-train-tensors-first-half/train_volumes', \"*.pt\"))\n        sh_paths = glob(os.path.join('../input/rsna-3d-train-tensors-first-half/train_volumes', \"*.pt\"))\n        \n        fh_list = []\n        sh_list = []\n        \n        for i in fh_paths:\n            fh_list.append(i.split('/')[-1][:-3])\n        \n        for i in sh_paths:\n            sh_list.append(i.split('/')[-1][:-3])\n        \n        # StudyInstanceUID 의 SLice 부분의 데이터를 전부 가져오는 것이다.\n        self.df_table_fh = self.df_table[self.df_table['StudyInstanceUID'].isin(fh_list)]\n        self.df_table_sh = self.df_table[self.df_table['StudyInstanceUID'].isin(sh_list)]\n        \n        # Image path\n        self.volume_dir1 = '../input/rsna-3d-train-tensors-first-half/train_volumes' \n        self.volume_dir2 = '../input/rsna-3d-train-tensors-second-half/train_volumes'\n    \n    def __getitem__(self, idx):\n        \n        if idx in self.df_table_fh.index:\n            patient = self.df_table_fh[self.df_table_fh.index == idx]['StudyInstanceUID'].iloc[0]\n            path = os.path.join(self.volume_dir1, f\"{patient}.pt\")\n            vol = torch.load(path).to(torch.float32)\n        \n        else:\n            patient = self.df_table_sh[self.df_table_sh.index == idx]['StudyInstanceUID'].iloc[0]\n            path = os.path.join(self.volume_dir2, f\"{patient}.pt\")\n            vol = torch.load(path).to(torch.float32)        \n        \n        if self.transform:\n            vol = self.transform(vol)    \n            \n        if 'C1_fracture' in self.df_table:\n            frac_targets = torch.as_tensor(self.df_table.iloc[idx][['C1_fracture', 'C2_fracture', 'C3_fracture', 'C4_fracture',\n                                                            'C5_fracture', 'C6_fracture', 'C7_fracture']].astype('float32').values)\n            \n            vert_targets = torch.as_tensor(self.df_table.iloc[idx][['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']].astype('float32').values)\n            frac_targets = frac_targets * vert_targets\n            \n            # train data\n            return vol.unsqueeze(0), frac_targets, vert_targets\n        \n        # Validataion\n        return vol.unsqueeze(0)\n        \n    def __len__(self):\n        return len(self.df_table)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-09-04T12:11:34.362274Z","iopub.execute_input":"2022-09-04T12:11:34.362934Z","iopub.status.idle":"2022-09-04T12:11:34.393894Z","shell.execute_reply.started":"2022-09-04T12:11:34.362887Z","shell.execute_reply":"2022-09-04T12:11:34.392912Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"markdown","source":"### Loss & Weights","metadata":{}},{"cell_type":"code","source":"def weighted_loss(y_pred_logit, y, reduction='mean', verbose=False):\n\n    neg_weights = (torch.tensor([7., 1, 1, 1, 1, 1, 1, 1]) if y_pred_logit.shape[-1] == 8 else torch.ones(y_pred_logit.shape[-1])).to(device)\n    pos_weights = (torch.tensor([14., 2, 2, 2, 2, 2, 2, 2]) if y_pred_logit.shape[-1] == 8 else torch.ones(y_pred_logit.shape[-1]) * 2.).to(device)\n\n    loss = torch.nn.functional.binary_cross_entropy_with_logits(\n        y_pred_logit,\n        y,\n        reduction='none',\n    )\n\n    if verbose:\n        print('loss', loss)\n\n    pos_weights = y * pos_weights.unsqueeze(0)\n    neg_weights = (1 - y) * neg_weights.unsqueeze(0)\n    all_weights = pos_weights + neg_weights\n\n    if verbose:\n        print('all weights', all_weights)\n\n    loss *= all_weights\n    if verbose:\n        print('weighted loss', loss)\n\n    norm = torch.sum(all_weights, dim=1).unsqueeze(1)\n    if verbose:\n        print('normalization factors', norm)\n\n    loss /= norm\n    if verbose:\n        print('normalized loss', loss)\n\n    loss = torch.sum(loss, dim=1)\n    if verbose:\n        print('summed up over patient_overall-C1-C7 loss', loss)\n\n    if reduction == 'mean':\n        return torch.mean(loss)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-09-04T09:45:41.624881Z","iopub.execute_input":"2022-09-04T09:45:41.625152Z","iopub.status.idle":"2022-09-04T09:45:41.637351Z","shell.execute_reply.started":"2022-09-04T09:45:41.625127Z","shell.execute_reply":"2022-09-04T09:45:41.636435Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def filter_nones(b):\n    return torch.utils.data.default_collate([v for v in b if v is not None])\n\ndef save_model(name, model):\n    torch.save(model.state_dict(), f'{name}.pt')","metadata":{"execution":{"iopub.status.busy":"2022-09-04T09:45:44.465219Z","iopub.execute_input":"2022-09-04T09:45:44.466098Z","iopub.status.idle":"2022-09-04T09:45:44.472755Z","shell.execute_reply.started":"2022-09-04T09:45:44.466059Z","shell.execute_reply":"2022-09-04T09:45:44.471368Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"class efficientNet3d(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = EfficientNet3D.from_name(\"efficientnet-b2\", override_params={'num_classes': 7}, in_channels=1)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features = n_features, bias=True)\n        \n        self.nn_fracture = torch.nn.Sequential(\n            torch.nn.Linear(1408, 7)\n        )\n        \n        self.nn_vertebrae = torch.nn.Sequential(\n            torch.nn.Linear(1408, 7)\n        )\n        \n    def forward(self, x):\n        x = self.net(x)\n        return self.nn_fracture(x), self.nn_vertebrae(x)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T10:22:50.606687Z","iopub.execute_input":"2022-09-04T10:22:50.607296Z","iopub.status.idle":"2022-09-04T10:22:50.615775Z","shell.execute_reply.started":"2022-09-04T10:22:50.607262Z","shell.execute_reply":"2022-09-04T10:22:50.614526Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"### Train 3D Model","metadata":{}},{"cell_type":"code","source":"# ----- Eval Pipeline\nPREDICT_MAX_BATCHES = 1e9\n\ndef evaluate_model(model, ds, max_batches = PREDICT_MAX_BATCHES, shuffle = False):\n    \n    torch.manual_seed(42)\n    model = model.to(device)\n    dl_test = torch.utils.data.DataLoader(ds, batch_size = BATCH_SIZE, shuffle = shuffle)\n    \n    with torch.no_grad():\n        model.eval()\n        frac_losses = []\n        vert_losses = []\n        sum_losses = []\n        \n        for i, (X, y_frac, y_vert) in enumerate(dl_test):\n            with autocast():\n                y_frac_pred, y_vert_pred = model.forward(X.to(device))\n                frac_loss = weighted_loss(y_frac_pred, y_frac.to(device)).item()\n                vert_loss = torch.nn.functional.binary_cross_entropy_with_logits(y_vert_pred, y_vert.to(device)).item()\n                loss = FRAC_LOSS_WEIGHT * frac_loss + vert_loss\n                \n                frac_losses.append(frac_loss)\n                vert_losses.append(vert_loss)\n                sum_losses.append(loss)\n                \n        return np.mean(frac_losses), np.mean(vert_losses), np.mean(sum_losses)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T11:36:20.566235Z","iopub.execute_input":"2022-09-04T11:36:20.566874Z","iopub.status.idle":"2022-09-04T11:36:20.581110Z","shell.execute_reply.started":"2022-09-04T11:36:20.566840Z","shell.execute_reply":"2022-09-04T11:36:20.579849Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# ----- Train Pipeline\nN_EPOCHS = 20\nONE_CYCLE_MAX_LR = 1e-4\nONE_CYCLE_PCT_START = 0.3\nFRAC_LOSS_WEIGHTS = 2.\nEFFNET_MAX_TRAIN_BATCHES = 4000\n\ndef train_model(ds_train, ds_eval, num):\n    torch.manual_seed(42)\n    name = f'{num}-fold effNet_model'\n    dl_train = torch.utils.data.DataLoader(ds_train, batch_size = BATCH_SIZE, \n                                           shuffle = True)\n    print(\"Hello World!\")    \n    for batch_idx, (X, y_frac, y_vert) in dl_train:\n        print(\"Hello World!\")\n    \n    \n    \n    model = efficientNet3d().to(device)\n    optim = torch.optim.Adam(model.parameters())\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr = ONE_CYCLE_MAX_LR, epochs = 1,\n                                                   steps_per_epoch = min(EFFNET_MAX_TRAIN_BATCHES, len(dl_train)),\n                                                   pct_start = ONE_CYCLE_PCT_START)\n    \n    model.train()\n    scaler = GradScaler()\n    \n    # ---------- 여기서 다시 짜야 한다.\n    \n    best_loss = 1e9\n    for idx in range(N_EPOCHS):\n        \n        frac_losses = []\n        vert_losses = []\n        sum_losses = []\n        \n        \n        for batch_idx, (X, y_frac, y_vert) in enumerate(dl_train):\n            \n            with autocast():\n                y_frac_pred, y_vert_pred = model.forward(X.to(device))\n\n                frac_loss = weighted_loss(y_frac_pred, y_frac.to(device))\n                vert_loss = torch.nn.functional.binary_cross_entropy_with_logits(y_vert_pred, y_vert.to(device))\n                loss = FRAC_LOSS_WEIGHT * frac_loss + vert_loss\n\n                frac_losses.append(frac_loss)\n                vert_losses.append(vert_loss)\n                sum_losses.append(loss)\n\n            optim.zero_grad()\n            scaler.scale(loss).backward()\n            scaler.step(optim)\n            scaler.update()\n            scheduler.step()\n        \n        frac_loss_mean, vert_loss_mean, sum_loss_mean = np.mean(frac_losses), np.mean(vert_losses), np.mean(sum_losses)\n        val_frac_loss_mean, val_vert_loss_mean, val_sum_loss_mean = evaluate_model(model, ds, max_batches = PREDICT_MAX_BATCHES, shuffle = True)\n        \n        print(f'{idx}/Epochs {best_loss} in Update {num}/5 SCORE!!')\n        print(f'===================== TRAIN ========================')\n        print(f'Train_frac_loss : {frac_loss_mean}, Train_vert_loss : {vert_loss_mean}, Train_sum_loss : {sum_loss_mean}')\n        print(f'===================== VALID ========================')\n        print(f'Valid_frac_loss : {val_frac_loss_mean}, Valid_vert_loss : {val_vert_loss_mean}, Valid_sum_loss : {val_sum_loss_mean}')\n        \n        if best_loss > sum_loss_mean:\n            best_loss = sum_loss_mean\n            print(\"============================\")\n            print(f\"{idx}/Epochs {best_loss} in Update {num}/5 3D Model !!\")\n            print(\"============================\")\n            save_model(name, model)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T11:38:17.301385Z","iopub.execute_input":"2022-09-04T11:38:17.301804Z","iopub.status.idle":"2022-09-04T11:38:17.320952Z","shell.execute_reply.started":"2022-09-04T11:38:17.301770Z","shell.execute_reply":"2022-09-04T11:38:17.319841Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"def gc_collect():\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-09-04T11:38:17.798360Z","iopub.execute_input":"2022-09-04T11:38:17.798737Z","iopub.status.idle":"2022-09-04T11:38:17.803625Z","shell.execute_reply.started":"2022-09-04T11:38:17.798706Z","shell.execute_reply":"2022-09-04T11:38:17.802611Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"# ----- FOLD LINE\neffnet_models = list()\nN_EPOCHS = 20\n\nfor fold in range(5):\n    gc_collect()    \n    \n    ds_train = RSNADataset(subset = 'train', df_table = train_df.query('split != @fold'), transform = augs)\n    ds_eval = RSNADataset(subset = 'valid', df_table = train_df.query('split == @fold'))\n    \n    train_model(ds_train, ds_eval, fold)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T11:41:21.649118Z","iopub.execute_input":"2022-09-04T11:41:21.649482Z","iopub.status.idle":"2022-09-04T11:41:22.445361Z","shell.execute_reply.started":"2022-09-04T11:41:21.649453Z","shell.execute_reply":"2022-09-04T11:41:22.443600Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"ds_train = RSNADataset(subset = 'train', df_table = train_df.query('split != 3'), transform = augs)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T12:11:41.415040Z","iopub.execute_input":"2022-09-04T12:11:41.415445Z","iopub.status.idle":"2022-09-04T12:11:41.654496Z","shell.execute_reply.started":"2022-09-04T12:11:41.415404Z","shell.execute_reply":"2022-09-04T12:11:41.653482Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"dl_train = torch.utils.data.DataLoader(ds_train, batch_size = BATCH_SIZE, \n                                           shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T12:11:42.388782Z","iopub.execute_input":"2022-09-04T12:11:42.389492Z","iopub.status.idle":"2022-09-04T12:11:42.395902Z","shell.execute_reply.started":"2022-09-04T12:11:42.389454Z","shell.execute_reply":"2022-09-04T12:11:42.394883Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"next(iter(dl_train))","metadata":{"execution":{"iopub.status.busy":"2022-09-04T12:11:44.694175Z","iopub.execute_input":"2022-09-04T12:11:44.695054Z","iopub.status.idle":"2022-09-04T12:11:44.778019Z","shell.execute_reply.started":"2022-09-04T12:11:44.695019Z","shell.execute_reply":"2022-09-04T12:11:44.776463Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"temp = next(iter(ds_train)","metadata":{"execution":{"iopub.status.busy":"2022-09-04T05:03:03.757357Z","iopub.status.idle":"2022-09-04T05:03:03.758165Z","shell.execute_reply.started":"2022-09-04T05:03:03.757907Z","shell.execute_reply":"2022-09-04T05:03:03.757932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp[0].size()","metadata":{"execution":{"iopub.status.busy":"2022-09-04T05:03:03.759709Z","iopub.status.idle":"2022-09-04T05:03:03.760577Z","shell.execute_reply.started":"2022-09-04T05:03:03.760301Z","shell.execute_reply":"2022-09-04T05:03:03.760326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}