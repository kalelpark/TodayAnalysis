{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Libraries","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install -qU ../input/for-pydicom/python_gdcm-3.0.14-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl ../input/for-pydicom/pylibjpeg-1.4.0-py3-none-any.whl --find-links frozen_packages --no-index","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:22:27.940563Z","iopub.execute_input":"2022-09-05T08:22:27.941457Z","iopub.status.idle":"2022-09-05T08:22:41.194560Z","shell.execute_reply.started":"2022-09-05T08:22:27.941333Z","shell.execute_reply":"2022-09-05T08:22:41.193328Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q kaggle_vol3d_classify -f ../input/cervical-spine-fracture-detection-npz-3d-volumes/frozen_packages --no-index","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:22:41.197652Z","iopub.execute_input":"2022-09-05T08:22:41.198074Z","iopub.status.idle":"2022-09-05T08:22:55.553079Z","shell.execute_reply.started":"2022-09-05T08:22:41.198031Z","shell.execute_reply":"2022-09-05T08:22:55.551691Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# ---- efficientNet3D offline  ---\nimport torch.nn as nn\nimport sys\nsys.path.append('../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D')\nfrom efficientnet_pytorch_3d import EfficientNet3D","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:24:41.382857Z","iopub.execute_input":"2022-09-05T08:24:41.383339Z","iopub.status.idle":"2022-09-05T08:24:41.390726Z","shell.execute_reply.started":"2022-09-05T08:24:41.383293Z","shell.execute_reply":"2022-09-05T08:24:41.389667Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.patches as patches\nimport seaborn as sns\nsns.set(style='darkgrid', font_scale=1.6)\nimport cv2\nimport os\nfrom os import listdir\nimport re\nimport gc\nimport random\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom tqdm.auto import tqdm\nfrom pprint import pprint\nfrom time import time\nimport itertools\nfrom skimage import measure\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nimport nibabel as nib\nfrom glob import glob\nimport warnings\nwarnings.filterwarnings('ignore')\n#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n#warnings.filterwarnings(\"ignore\", category=UserWarning)\n#warnings.filterwarnings(\"ignore\", category=FutureWarning)\nimport zipfile\nfrom scipy import ndimage\nfrom sklearn.model_selection import train_test_split, GroupKFold\nfrom joblib import Parallel, delayed\nfrom PIL import Image\nfrom dipy.denoise.nlmeans import nlmeans\nfrom dipy.denoise.noise_estimate import estimate_sigma\nfrom kaggle_volclassif.utils import interpolate_volume\nfrom skimage import exposure\n\n# Pytorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport kornia\nimport kornia.augmentation as augmentation","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:31:18.442835Z","iopub.execute_input":"2022-09-05T08:31:18.443476Z","iopub.status.idle":"2022-09-05T08:31:18.461368Z","shell.execute_reply.started":"2022-09-05T08:31:18.443439Z","shell.execute_reply":"2022-09-05T08:31:18.460155Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"## Setting & Data","metadata":{}},{"cell_type":"code","source":"# Set random seeds\ndef set_seed(seed=0):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\nset_seed()\n\nBATCH_SIZE = 4\nLEARNING_RATE = 0.0001\nN_EPOCHS = 20\nPATIENCE = 3\nEXPERIMENTAL = False\nAUGMENTATIONS = True\n\n# Config device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Load metadata\ntrain_df = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/train.csv\")\ntrain_bbox = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/train_bounding_boxes.csv\")\ntest_df = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/test.csv\")\nss = pd.read_csv(\"../input/rsna-2022-cervical-spine-fracture-detection/sample_submission.csv\")\n\n\nbad_scans = ['1.2.826.0.1.3680043.20574','1.2.826.0.1.3680043.29952']\n\nfor uid in bad_scans:\n    train_df.drop(train_df[train_df['StudyInstanceUID']==uid].index, axis=0, inplace=True)\n\n    \ndebug = False\nif len(ss)==3:\n    debug = True\n    \n    # Fix mismatch with test_images folder\n    test_df = pd.DataFrame(columns = ['row_id','StudyInstanceUID','prediction_type'])\n    for i in ['1.2.826.0.1.3680043.22327','1.2.826.0.1.3680043.25399','1.2.826.0.1.3680043.5876']:\n        for j in ['C1','C2','C3','C4','C5','C6','C7','patient_overall']:\n            test_df = test_df.append({'row_id':i+'_'+j,'StudyInstanceUID':i,'prediction_type':j},ignore_index=True)\n    \n    # Sample submission\n    ss = pd.DataFrame(test_df['row_id'])\n    ss['fractured'] = 0.5\n    \n\nif AUGMENTATIONS:\n    augs = transforms.Compose([\n        augmentation.RandomRotation3D((0,0,30), resample='bilinear', p=0.5, same_on_batch=False, keepdim=True),\n        #augmentation.RandomHorizontalFlip3D(same_on_batch=False, p=0.5, keepdim=True),\n        ])\nelse:\n    augs=None","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:31:19.445618Z","iopub.execute_input":"2022-09-05T08:31:19.446312Z","iopub.status.idle":"2022-09-05T08:31:19.533313Z","shell.execute_reply.started":"2022-09-05T08:31:19.446277Z","shell.execute_reply":"2022-09-05T08:31:19.532344Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"### CustomDataset","metadata":{}},{"cell_type":"code","source":"class RSNADataset(Dataset):\n    # Initialise\n    def __init__(self, subset='train', df_table = train_df, transform=None):\n        super().__init__()\n        \n        self.subset = subset\n        self.df_table = df_table.reset_index(drop=True)\n        self.transform = transform\n        self.targets = ['C1','C2','C3','C4','C5','C6','C7','patient_overall']\n        \n        # Identify files in each of the two datasets\n        fh_paths = glob(os.path.join('../input/rsna-3d-train-tensors-first-half/train_volumes', \"*.pt\"))\n        sh_paths = glob(os.path.join('../input/rsna-3d-train-tensors-second-half/train_volumes', \"*.pt\"))\n        \n        fh_list = []\n        sh_list = []\n        for i in fh_paths:\n            fh_list.append(i.split('/')[-1][:-3])\n        \n        for i in sh_paths:\n            sh_list.append(i.split('/')[-1][:-3])\n        \n        self.df_table_fh = self.df_table[self.df_table['StudyInstanceUID'].isin(fh_list)]\n        self.df_table_sh = self.df_table[self.df_table['StudyInstanceUID'].isin(sh_list)]\n        \n        # Image paths\n        self.volume_dir1 = '../input/rsna-3d-train-tensors-first-half/train_volumes'  # <=1000 patient\n        self.volume_dir2 = '../input/rsna-3d-train-tensors-second-half/train_volumes' # >1000 patient\n\n        # Populate labels\n        self.labels = self.df_table[self.targets].values\n        \n    # Get item in position given by index\n    def __getitem__(self, index):\n        if index in self.df_table_fh.index:\n            patient = self.df_table_fh[self.df_table_fh.index==index]['StudyInstanceUID'].iloc[0]\n            path = os.path.join(self.volume_dir1, f\"{patient}.pt\")\n            vol = torch.load(path).to(torch.float32)\n        else:\n            patient = self.df_table_sh[self.df_table_sh.index==index]['StudyInstanceUID'].iloc[0]\n            path = os.path.join(self.volume_dir2, f\"{patient}.pt\")\n            vol = torch.load(path).to(torch.float32)\n        \n        # Data augmentations\n        if self.transform:\n            vol = self.transform(vol)\n        \n        return vol.unsqueeze(0), self.labels[index]\n\n    # Length of dataset\n    def __len__(self):\n        return len(self.df_table['StudyInstanceUID'])","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:31:20.259201Z","iopub.execute_input":"2022-09-05T08:31:20.259966Z","iopub.status.idle":"2022-09-05T08:31:20.274002Z","shell.execute_reply.started":"2022-09-05T08:31:20.259919Z","shell.execute_reply":"2022-09-05T08:31:20.272891Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index()\ntrain_df.drop(['index'], axis = 1, inplace = True)\ntrain_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:31:20.881220Z","iopub.execute_input":"2022-09-05T08:31:20.881613Z","iopub.status.idle":"2022-09-05T08:31:20.898726Z","shell.execute_reply.started":"2022-09-05T08:31:20.881563Z","shell.execute_reply":"2022-09-05T08:31:20.897389Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"N_FOLDS = 5\n\nsplit = GroupKFold(N_FOLDS)\nfor k, (_, test_idx) in enumerate(split.split(train_df, groups=train_df.StudyInstanceUID)):\n    train_df.loc[test_idx, 'split'] = k\n\ntrain_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:31:21.585823Z","iopub.execute_input":"2022-09-05T08:31:21.586649Z","iopub.status.idle":"2022-09-05T08:31:21.627101Z","shell.execute_reply.started":"2022-09-05T08:31:21.586570Z","shell.execute_reply":"2022-09-05T08:31:21.626141Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"### Setting for Train","metadata":{}},{"cell_type":"code","source":"def gc_collect():\n    gc.collect()\n    torch.cuda.empty_cache()\n    \ndef return_model():\n    model = EfficientNet3D.from_name(\"efficientnet-b2\", override_params={'num_classes': 8}, in_channels=1)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:31:22.661971Z","iopub.execute_input":"2022-09-05T08:31:22.662551Z","iopub.status.idle":"2022-09-05T08:31:22.668030Z","shell.execute_reply.started":"2022-09-05T08:31:22.662517Z","shell.execute_reply":"2022-09-05T08:31:22.666997Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.BCEWithLogitsLoss(reduction='none')\n\ncompetition_weights = {\n    '-' : torch.tensor([1, 1, 1, 1, 1, 1, 1, 7], dtype=torch.float, device=device),\n    '+' : torch.tensor([2, 2, 2, 2, 2, 2, 2, 14], dtype=torch.float, device=device),\n}\n\ndef competiton_loss_row_norm(y_hat, y):\n    loss = loss_fn(y_hat, y.to(y_hat.dtype))\n    weights = y * competition_weights['+'] + (1 - y) * competition_weights['-']\n    loss = (loss * weights).sum(axis=1)\n    w_sum = weights.sum(axis=1)\n    loss = torch.div(loss, w_sum)\n    return loss.mean()","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:31:23.397354Z","iopub.execute_input":"2022-09-05T08:31:23.397757Z","iopub.status.idle":"2022-09-05T08:31:23.406734Z","shell.execute_reply.started":"2022-09-05T08:31:23.397723Z","shell.execute_reply":"2022-09-05T08:31:23.405470Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(dl_valid, model):\n    val_loss_acc = 0\n    valid_count = 0\n    model.eval()\n    with torch.no_grad():\n        for val_imgs, val_labels in dl_valid:\n            val_imgs = val_imgs.to(device)\n            val_labels = val_labels.to(device)\n            \n            val_preds = model(val_imgs)\n            val_L = competition_weights(val_preds, val_labels)\n            \n            val_loss_acc += val_L.item()\n            valid_count += 1\n        \n        \n        return val_loss_acc/valid_count","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:31:24.034701Z","iopub.execute_input":"2022-09-05T08:31:24.035087Z","iopub.status.idle":"2022-09-05T08:31:24.041838Z","shell.execute_reply.started":"2022-09-05T08:31:24.035056Z","shell.execute_reply":"2022-09-05T08:31:24.040814Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def save_model(model, fold):\n    torch.save(model.state_dict(), f'{fold}/5_EffV2_model.pt')","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:31:24.700977Z","iopub.execute_input":"2022-09-05T08:31:24.701650Z","iopub.status.idle":"2022-09-05T08:31:24.706629Z","shell.execute_reply.started":"2022-09-05T08:31:24.701588Z","shell.execute_reply":"2022-09-05T08:31:24.705667Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def train_model(dl_train, dl_valid, fold):\n    loss_hist = []\n    val_loss_hist = []\n    best_valid = 1.0\n    \n    model = return_model()\n    model.to(device)\n    optimizer = optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)\n    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n    \n    for epoch in tqdm(range(N_EPOCHS)):\n        loss_acc = 0\n        train_count = 0\n        \n        for imgs, labels in dl_train:\n            imgs = imgs.to(device)\n            labels = labels.to(device)\n            \n            preds = model(imgs)\n            L = competiton_loss_row_norm(preds, labels)\n            L.backward()\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            loss_acc += L.detach().item()\n            train_count += 1\n        \n        scheduler.step()\n        loss_acc /= train_count\n        val_loss = evaluate_model(dl_valid, model)\n\n        # append History\n        loss_hist.append(loss_acc)\n        val_loss_hist.append(val_loss)\n                \n        print(f'{fold}/5 | {epoch}/{N_EPOCHS} | train_loss {loss_acc} | valid_loss : {val_loss}')\n        \n        if best_valid > val_loss:\n            best_valid = val_loss\n            save_model(model, fold)\n            ","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:32:06.597938Z","iopub.execute_input":"2022-09-05T08:32:06.598296Z","iopub.status.idle":"2022-09-05T08:32:06.608112Z","shell.execute_reply.started":"2022-09-05T08:32:06.598267Z","shell.execute_reply":"2022-09-05T08:32:06.606951Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"def start_model_train_eval():\n    for fold in range(N_FOLDS):\n        train_dataset = RSNADataset(subset='train', df_table = train_df.query('split != @fold'), transform = augs)\n        valid_dataset = RSNADataset(subset='valid', df_table = train_df.query('split == @fold'), transform = None)\n\n        dl_train = DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n        dl_valid = DataLoader(dataset = valid_dataset, batch_size = BATCH_SIZE, shuffle = False)\n\n        gc_collect()        \n\n        train_model(dl_train, dl_valid, fold)\n        \nstart_model_train_eval()","metadata":{"execution":{"iopub.status.busy":"2022-09-05T08:32:06.847693Z","iopub.execute_input":"2022-09-05T08:32:06.848255Z"},"trusted":true},"execution_count":null,"outputs":[]}]}