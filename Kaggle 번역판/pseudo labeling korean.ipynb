{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style='background:#F9EEEC; border:0; color: #EA7B67'><center>Pseudo Labeing</center></h1>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"**This Kernel translated into Korean. If you not Korean, Check : <a href=\"https://www.kaggle.com/code/cdeotte/pseudo-labeling-qda-0-969#Step-3-&-4---Add-pseudo-label-data-and-build-second-model\">LINK</a>**\n\n<h1 style='background:#F9EEEC; border:0; color: #EA7B67'><center>TABLE OF CONTENTS</center></h1>\n\n[1. Pseudo Labeling with QDA scores LB](#1)\n    \n[2. What is Pseudo Labeling?](#2)    \n\n[3. Why does Pseudo Labeling work?](#3)        \n\n[4. Step 1 and 2 - Build first QDA model and predict test](#4)  \n\n[5. Step 3 & 4 - Add pseudo label data and build second model](#5)    \n\n[6. Submit Predictions](#6)  \n\n[7. Conclusion](#7)\n\n<h1 style='background:#F9EEEC; border:0; color: #EA7B67'><center>START</center></h1>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# **<span style=\"color:#4686C8;\">Pseudo Labeling with QDA scores LB</span>**\n\n**\"Instant Gratification\" Competition에서는, 512개의 행과 40개의 열로 이루어진 512개의 모델이 있습니다. 40개의 변수가 있는 quadratic model은 더 많은 행을 원합니다.**\n\n**Pseudo Labeling을 사용한다면, 400개의 행을 얻을 수 있으며, LB 와 PB의 성능을 향상시킬 수 있습니다.**\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# **<span style=\"color:#4686C8;\">What is Pseudo Labeling?</span>**\n\n**Pseudo Labeling은 test data에서 예측한 것들을 trianing data에 추가하는 과정입니다.**\n\n**Pseudo Labeling은 5가지의 절차에 따라 수행됩니다.**\n\n**- 1. Training Data를 가지고, 모델을 생성합니다.**\n\n**- 2. test data에 대해 예측합니다.**\n\n**- 3. Training Data에 확신을 가진 test data를 추가합니다.**\n\n**- 4. 결합된 데이터를 가지고, 새로운 모델을 생성합니다.**\n\n**- 5. 새로운 모델로 test data를 예측한 후, Kaggle에 제출합니다.**\n\n**Image로 과정을 확인하고 싶다면, <a href=\"https://www.kaggle.com/code/cdeotte/pseudo-labeling-qda-0-969#Why-does-Pseudo-Labeling-work?\">LINK</a>를 참고하시기 바랍니다.**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n# **<span style=\"color:#4686C8;\">Why does Pseudo Labeling work?</span>**\n\n**<a href=\"https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/89003\">LINK</a>에서 Pseudo Labeling을 활용하여, 1등이 되었을 때, 매우 감격스러웠다.**\n\n**이전에 학습된 모델에 의해 레이블이 지정된 알 수 없는 데이터로 훈련하면 동일한 모델이 어떻게 향상됩니까?**\n\n**모델이 이미 정보를 알고 있기에 가능한 것이 아니라, 모델이 예측하였기 때문에 가능한 것입니다.**\n\n## Load Data","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.metrics import roc_auc_score\n\ntrain = pd.read_csv('../input/instant-gratification/train.csv')\ntest = pd.read_csv('../input/instant-gratification/test.csv')\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-30T02:21:17.115420Z","iopub.execute_input":"2022-08-30T02:21:17.115838Z","iopub.status.idle":"2022-08-30T02:21:44.017988Z","shell.execute_reply.started":"2022-08-30T02:21:17.115805Z","shell.execute_reply":"2022-08-30T02:21:44.016249Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n# **<span style=\"color:#4686C8;\">Step 1 and 2 - Build first QDA model and predict test</span>**","metadata":{}},{"cell_type":"code","source":"cols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\n\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\nfor i in range(512):\n    train2 = train[train['wheezy-copper-turtle-magic'] == i]\n    test2 = test[test['wheezy-copper-turtle-magic'] == i]\n    \n    # 먼저 같은 데이터만을 가져옵니다.\n    if (len(train2) == 0) & (len(test2) == 0):\n        continue\n    \n    # Train, Test 2가지로 분류해줍니다.\n    idx1 = train2.index\n    idx2 = test2.index\n    \n    # index 초기화\n    train2.reset_index(drop = True, inplace = True)\n    \n    # Feature Selection\n    sel = VarianceThreshold(threshold = 1.5).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    \n    if len(test2) > 0:\n        test3 = sel.transform(test2[cols])\n    \n    skf = StratifiedKFold(n_splits = 11, random_state = 42, shuffle = True)\n    \n    # wheezy-copper-turtle-magic와 값이 같은 것을 고르면 됩니다.\n    \n    for train_index, test_index in skf.split(train3, train2['target']):\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        clf.fit(train3[train_index, :], train2.loc[train_index]['target'])\n        oof[idx1[test_index]] = clf.predict_proba(train3[test_index, :])[:, 1]\n        if len(test2) > 0:\n            preds[idx2] += clf.predict_proba(test3)[:, 1] / skf.n_splits\n        \nauc = roc_auc_score(train['target'], oof)\nprint('QDA scores CV = ', round(auc, 5))","metadata":{"execution":{"iopub.status.busy":"2022-08-30T03:23:20.930173Z","iopub.execute_input":"2022-08-30T03:23:20.930699Z","iopub.status.idle":"2022-08-30T03:24:56.437151Z","shell.execute_reply.started":"2022-08-30T03:23:20.930664Z","shell.execute_reply":"2022-08-30T03:24:56.435753Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n# **<span style=\"color:#4686C8;\">Step 3 & 4 - Add pseudo label data and build second model</span>**","metadata":{}},{"cell_type":"code","source":"test['target'] = preds\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\nfor k in range(512):\n    train2 = train[train['wheezy-copper-turtle-magic'] == k]\n    train2p = train2.copy()\n    idx1 = train2.index\n\n    test2 = test[test['wheezy-copper-turtle-magic'] == k]\n    test2p = test2[(test2['target'] <= 0.01) | (test2['target'] >= 0.99)].copy()\n    \n    test2p.loc[test2p['target'] >= 0.5, 'target'] = 1\n    test2p.loc[test2p['target'] < 0.5, 'target'] = 0\n    \n    train2p = pd.concat([train2p, test2p], axis = 0)\n    train2p.reset_index(drop = True, inplace = True)\n    \n    sel = VarianceThreshold(threshold = 1.5).fit(train2p[cols])\n    train3p = sel.transform(train2p[cols])\n    train3 = sel.transform(train2[cols])\n    \n    if len(test2) > 0:\n        test3 = sel.transform(test2[cols])\n    \n    skf = StratifiedKFold(n_splits = 11, random_state = 42, shuffle = True)\n    for train_index, test_index in skf.split(train3p, train2p['target']):\n        test_index3 = test_index[test_index<len(train3)]\n        \n        clf = QuadraticDiscriminantAnalysis(reg_param = 0.5)\n        clf.fit(train3p[train_index, :], train2p.loc[train_index]['target'])\n        oof[idx1[test_index3]] = clf.predict_proba(train3[test_index3, :])[:, 1]\n        \n        if len(test2) > 0:\n            preds[test2.index] += clf.predict_proba(test3)[:, 1] / skf.n_splits\n\nauc = roc_auc_score(train['target'],oof)\nprint('Pseudo Labeled QDA scores CV =',round(auc,5))","metadata":{"execution":{"iopub.status.busy":"2022-08-30T03:43:16.214849Z","iopub.execute_input":"2022-08-30T03:43:16.215289Z","iopub.status.idle":"2022-08-30T03:45:23.074041Z","shell.execute_reply.started":"2022-08-30T03:43:16.215256Z","shell.execute_reply":"2022-08-30T03:45:23.072758Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n# **<span style=\"color:#4686C8;\">Submit Predictions</span>**","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\nsub['target'] = preds\nsub.to_csv('submission.csv',index=False)\n\nimport matplotlib.pyplot as plt\nplt.hist(preds,bins=100)\nplt.title('Final Test.csv predictions')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n# **<span style=\"color:#4686C8;\">Conclusion</span>**\n\n**요번 시간에는 Pseudo Labeling이 무엇인지, 어떻게 작동하는지 배웠습니다. 해당 대회를 통하여, Pseudo Labeling을 사용하는 경우 0.005가 개선되는 것을 알 수 있었습니다.**\n\n**해당 대회에 Solution을 제출하는 경우, 공개 데이터인 test와 비공개 데이터를 모두 합쳐 작동하기 때문에, 데이터 양이 2배 더 많아집니다.**","metadata":{}}]}